{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchcam.associativeNN import aCAM_NOR\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# from scipy.signal import correlate as scipy_autocorrelate\n",
    "# # from scipy.signal import correlation_lags as scipy_correlation_lags\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "# import torch.nn as nn\n",
    "import matplotlib.cm as cm\n",
    "# from matplotlib.ticker import LinearLocator\n",
    "# import ipywidgets as widgets\n",
    "# from ipywidgets import interact, fixed\n",
    "# from IPython.display import display\n",
    "from inspect import getargspec\n",
    "# from matplotlib import rc_params as rc\n",
    "import os\n",
    "import sys\n",
    "dir_name = os.getcwd()\n",
    "parent_dir_name = os.path.dirname(dir_name)\n",
    "sys.path.insert(0, parent_dir_name)\n",
    "from modules.continuous_model import CAMSimilarity\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting DRAM MAC\n",
    "If temporal encoding: use only the max X value 0.9 V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = np.load(\"non-linearity.npy\", allow_pickle=True).item()\n",
    "\n",
    "Y, X = np.meshgrid(data['Vstore'], data['Vin'])\n",
    "Z = data['Iout'].T * 1e+6\n",
    "\n",
    "# # Plot the 3D figure of the fitted function and the residuals.\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "def get_basis(x, y, max_order=4):\n",
    "    \"\"\"Return the fit basis polynomials: 1, x, x^2, ..., xy, x^2y, ... etc.\"\"\"\n",
    "    basis = []\n",
    "    for i in range(max_order+1):\n",
    "        for j in range(max_order - i +1):\n",
    "            basis.append(x**j * y**i)\n",
    "    return basis\n",
    "\n",
    "def poly_torch(x, y, c):\n",
    "    \"\"\"Compute the polynomial basis and sum the elements weighted by the coefficients.\"\"\"\n",
    "    max_order = int((2 * len(c))**0.5 - 1)\n",
    "    basis_sum = torch.zeros_like(x)\n",
    "    idx = 0\n",
    "    for i in range(max_order+1):\n",
    "        for j in range(max_order - i + 1):\n",
    "            basis_sum += c[idx] * (x**j) * (y**i)\n",
    "            # print(j, i)\n",
    "            idx += 1\n",
    "    return basis_sum\n",
    "\n",
    "# # Linear with X\n",
    "# X = X.max()*np.ones_like(X)\n",
    "# Z = np.expand_dims(Z[-1], axis=0).repeat(Z.shape[0], axis=0)\n",
    "\n",
    "# We need to ravel the meshgrids of X, Y points to a pair of 1-D arrays.\n",
    "x, y = X.ravel(), Y.ravel()\n",
    "### If temporal encoding, x always Vds=0.9 V ###\n",
    "offset = 0.45\n",
    "Y = Y-offset\n",
    "x, y, Z = X[-1], Y[-1], Z[-1]\n",
    "X, Y = X[-1], Y[-1]\n",
    "\n",
    "# Maximum order of polynomial term in the basis.\n",
    "max_order = 3\n",
    "basis = get_basis(x, y, max_order)\n",
    "# Linear, least-squares fit.\n",
    "A = np.vstack(basis).T\n",
    "b = Z.ravel()\n",
    "c, r, rank, s = np.linalg.lstsq(A, b, rcond=None)\n",
    "\n",
    "print('Fitted parameters:')\n",
    "print(c)\n",
    "\n",
    "fit = poly_torch(torch.tensor(X), torch.tensor(Y), torch.tensor(c))\n",
    "# fit = poly_torch(torch.tensor(x), torch.tensor(y), torch.tensor(c))\n",
    "\n",
    "rms = np.sqrt(np.mean((Z - fit.numpy())**2))\n",
    "# rms_torch = np.sqrt(np.mean((fit_torch.numpy() - fit)**2))\n",
    "r2 = r2_score(Z, fit)\n",
    "print('R² =', r2, '\\tRMS residual =', rms, '\\t STD of Iout =', np.std(Z))\n",
    "\n",
    "# Plot the 3D figure of the fitted function and the residuals.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.plot_surface(X, Y, fit, cmap='viridis')\n",
    "ax.plot_surface(X, Y, Z, cmap='hot')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 4th order polynomial coefficients should be:\n",
    "# c = [-1.3243,      -4.55143622,  37.90728197, -48.45341553,  -1.40523441,\n",
    "#     -0.41149789,  -6.31034117, -15.68601137,  99.32576954,  42.98316917,\n",
    "#     -91.14142385, -73.43655634, -38.19116262, 137.86408319, -14.24518563]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit linear model from poly model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = 0.45\n",
    "# Custom linear model z = a*x*y + b (requires already dealing with offsets, x=x-0.45, y=y-0.45)\n",
    "def get_custom_basis(x, y):\n",
    "    basis = []\n",
    "    basis.append(x**0 * y**0) # 0th order\n",
    "    basis.append(x**1 * y**1) # 2nd order\n",
    "    return basis\n",
    "\n",
    "def poly_torch_linear(x, y, c):\n",
    "    \"\"\"Compute the polynomial basis and sum the elements weighted by the coefficients.\"\"\"\n",
    "    basis_sum = c[0] * (x**0) * (y**0) # 0th order\n",
    "    basis_sum = c[1] * (x**1) * (y**1) # 2nd order\n",
    "    return basis_sum\n",
    "\n",
    "basis = get_custom_basis(x-offsets, y-offsets)\n",
    "\n",
    "# Linear, least-squares fit.\n",
    "A = np.vstack(basis).T\n",
    "b = fit.ravel()\n",
    "c_linear, r, rank, s = np.linalg.lstsq(A, b, rcond=None)\n",
    "\n",
    "print('Fitted parameters:')\n",
    "print(c_linear)\n",
    "\n",
    "# fit_linear = poly_torch_linear(torch.tensor(X-offsets), torch.tensor(Y-offsets), torch.tensor(c_linear))\n",
    "fit_linear = poly_torch_linear(torch.tensor(x-offsets), torch.tensor(y-offsets), torch.tensor(c_linear))\n",
    "\n",
    "rms = np.sqrt(np.mean((fit.numpy() - fit_linear.numpy())**2))\n",
    "rms_torch = np.sqrt(np.mean((fit_linear.numpy() - fit.numpy())**2))\n",
    "r2 = r2_score(fit, fit_linear)\n",
    "print('R² =', r2, '\\tRMS residual =', rms, '\\t STD of Iout =', np.std(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the DRAM MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"non-linearity.npy\", allow_pickle=True).item()\n",
    "Vds = data.get(\"Vin\")\n",
    "# Temporal encoding\n",
    "Vds = Vds*0+0.9\n",
    "Vgs = data.get(\"Vstore\")\n",
    "Ids = data.get(\"Iout\")\n",
    "Ids *= 1e6\n",
    "\n",
    "vds_min = -np.inf\n",
    "vds_max = np.inf\n",
    "\n",
    "vgs_min = -np.inf\n",
    "vgs_max = np.inf\n",
    "\n",
    "VGS_vals = np.linspace(0,49,10)\n",
    "fig, ax = plt.subplots(2)\n",
    "fig.set_figwidth(4)\n",
    "fig.set_figheight(5)\n",
    "cmap=cm.coolwarm\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "for i, VGS_index in enumerate(VGS_vals):\n",
    "    if Vgs[int(VGS_index)] < vgs_max and Vgs[int(VGS_index)] > vgs_min:\n",
    "        ax[0].plot(Vds, Ids[int(VGS_index),:], 'o', ms=2, c=cmap(i/len(VGS_vals)))\n",
    "\n",
    "VDS_vals = np.linspace(0,49,10)\n",
    "# VDS_vals = [49]\n",
    "for i, VDS_index in enumerate(VDS_vals):\n",
    "    if Vds[int(VDS_index)] < vds_max and Vds[int(VDS_index)] > vds_min:\n",
    "        ax[1].plot(Vgs, Ids[:, int(VDS_index)], 'o', ms=2, c=cmap(i/len(VDS_vals)))\n",
    "        \n",
    "fig.tight_layout()\n",
    "\n",
    "#surface plot of the current\n",
    "Vds3d, Vgs3d = np.meshgrid(Vds, Vgs)\n",
    "# fig = plt.figure()\n",
    "# ax3d = plt.axes(projection ='3d')\n",
    "# surf = ax3d.plot_surface(Vds3d, Vgs3d, Ids, cmap=cm.coolwarm)\n",
    "# ax3d.set_xlabel(\"Vds [V]\")\n",
    "# ax3d.set_ylabel(\"Vgs [V]\")\n",
    "# ax3d.set_zlabel(\"I [µA]\")\n",
    "# ax3d.set_title(\"Current\")\n",
    "\n",
    "condition = (Vds3d < vds_max) * (Vds3d > vds_min) * (Vgs3d < vgs_max) * (Vgs3d > vgs_min)\n",
    "\n",
    "# Polynomial fit from regression\n",
    "Ids_fit = fit.T\n",
    "\n",
    "# Plot polynomial fit\n",
    "for i, VGS_index in enumerate(VGS_vals):\n",
    "    if Vgs[int(VGS_index)] < vgs_max and Vgs[int(VGS_index)] > vgs_min:\n",
    "        ax[0].plot(Vds, Ids_fit[int(VGS_index),:], '-', linewidth=2, c=cmap(i/len(VGS_vals)), label=f'{Vgs[int(VGS_index)]:.2f} V')\n",
    "        \n",
    "# ax[0].set_xlim([vds_min, vds_max]) if np.isfinite(vds_min) and np.isfinite(vds_max) else None\n",
    "# # ax[0].set_ylim([-0.1, 0.1])\n",
    "ax[0].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize=fontsize/2, frameon=False)\n",
    "ax[0].set_xlabel(\"Input voltage (V)\", fontsize=fontsize)\n",
    "ax[0].set_ylabel(\"Output current (µA)\", fontsize=fontsize)\n",
    "\n",
    "# Linear fit from regression\n",
    "# Ids_fit_linear = fit_linear.T\n",
    "\n",
    "# Plot linear fit fitted from polynomial fit\n",
    "# for i, VGS_index in enumerate(VGS_vals):\n",
    "#     if Vgs[int(VGS_index)] < vgs_max and Vgs[int(VGS_index)] > vgs_min:\n",
    "#         ax[0].plot(Vds, Ids_fit_linear[int(VGS_index),:], '--d', ms=2, linewidth=0.5, c=cmap(i/len(VGS_vals)))\n",
    "\n",
    "for i, VDS_index in enumerate(VDS_vals):\n",
    "    if Vds[int(VDS_index)] < vds_max and Vds[int(VDS_index)] > vds_min:\n",
    "        # ax[1].plot(Vgs, Ids_fit[:,int(VDS_index)], '-', linewidth=2, c=cmap(i/len(VDS_vals)), label=f\"{Vds[int(VDS_index)]:.2f} V\")\n",
    "        # Temporal encoding\n",
    "        ax[1].plot(Vgs, Ids_fit, '-', linewidth=2, c=cmap(i/len(VDS_vals)), label=f\"Vds={Vds[int(VDS_index)]:.2f}\")\n",
    "        \n",
    "ax[1].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', fontsize=fontsize/2, frameon=False)\n",
    "ax[1].set_xlabel(\"Stored voltage (V)\", fontsize=fontsize)\n",
    "ax[1].set_ylabel(\"Output current (µA)\", fontsize=fontsize)\n",
    "        \n",
    "# for i, VDS_index in enumerate(VDS_vals):\n",
    "#     if Vds[int(VDS_index)] < vds_max and Vds[int(VDS_index)] > vds_min:\n",
    "#         # ax[1].plot(Vgs, Ids_fit_linear[:,int(VDS_index)], '--d', ms=2, linewidth=0.5, c=cmap(i/len(VDS_vals)))\n",
    "#         ax[1].plot(Vgs, Ids_fit_linear, '--d', ms=2, linewidth=0.5, c=cmap(i/len(VDS_vals)))\n",
    "        \n",
    "ax[1].set_xlim([vgs_min, vgs_max]) if np.isfinite(vgs_min) and np.isfinite(vgs_max) else None\n",
    "fig.tight_layout()\n",
    "file_out = 'DRAM_IvsV'\n",
    "for fmt in ['png', 'svg', 'pdf']:\n",
    "    plt.savefig(file_out + '.%s' % fmt, format=fmt, dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trye optimize through backprop layer-wize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot scatter linear versus nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = 0.2\n",
    "\n",
    "scaled_Ids_fit_linear = Ids_fit_linear * scaling\n",
    "scaled_Ids_fit = Ids_fit * scaling\n",
    "\n",
    "clamped_Ids_fit_linear = torch.clamp(scaled_Ids_fit_linear, 0.45, 0.9)\n",
    "clamped_Ids_fit = torch.clamp(scaled_Ids_fit, 0.45, 0.9)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(4)\n",
    "\n",
    "ax[0].scatter(scaled_Ids_fit_linear.numpy(), scaled_Ids_fit_linear.numpy(), s=1, color='darkblue', label='Linear model')\n",
    "ax[0].scatter(scaled_Ids_fit_linear.numpy(), scaled_Ids_fit.numpy(), s=1, color='darkred', label='Nonlinear model')\n",
    "ax[0].set_xlabel(f'X')\n",
    "ax[0].set_ylabel(f'Y')\n",
    "ax[0].legend(loc='upper right')\n",
    "\n",
    "ax[1].scatter(scaled_Ids_fit_linear.numpy(), clamped_Ids_fit_linear.numpy(), s=1, color='darkblue', label='Clamped linear model')\n",
    "ax[1].scatter(scaled_Ids_fit_linear.numpy(), clamped_Ids_fit.numpy(), s=1, color='darkred', label='Clamped nonlinear model')\n",
    "# ax[1].scatter(scaled_Ids_fit_linear.numpy(), soft_clipper(scaled_Ids_fit).numpy(), s=1, color='darkgreen', label='Smooth clamped nonlinear model')\n",
    "ax[1].set_xlabel(f'X')\n",
    "ax[1].set_ylabel(f'Y')\n",
    "ax[1].legend(loc='lower right')\n",
    "\n",
    "ax[2].hist(scaled_Ids_fit_linear.flatten().numpy(), color='darkblue', alpha=0.5)\n",
    "ax[2].hist(scaled_Ids_fit.flatten().numpy(), color='darkred', alpha=0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Number of saturated val in Linear model: Low bound {(clamped_Ids_fit_linear==0.45).sum().item()}\\tHigh bound {(clamped_Ids_fit_linear==0.9).sum().item()}')\n",
    "print(f'Number of saturated val in Nonlinear model: Low bound {(clamped_Ids_fit==0.45).sum().item()}\\tHigh bound {(clamped_Ids_fit==0.9).sum().item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAC(n_levels, Vmin, Vmax, Inp):\n",
    "    \"\"\"\n",
    "    this function simulaties the DAC operation by quantizing the input Inp to resolution bits\n",
    "    \"\"\"\n",
    "    # uantize the input\n",
    "    q_step = (Vmax-Vmin)/(n_levels-1)\n",
    "    # q_step_x = (Vmax-Vmin)/n_levels\n",
    "    print(f'q_step is {q_step:.4f}')\n",
    "    Out = q_step * torch.round(Inp/q_step)\n",
    "    return Out\n",
    "\n",
    "#plot quantization\n",
    "in_vec = torch.linspace(0, 1, 500)\n",
    "n_levels = 6\n",
    "out_vec = DAC(n_levels, 0, 1, in_vec)\n",
    "plt.plot(in_vec, out_vec, 'o') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftClamp(nn.Module):\n",
    "    def __init__(self, xmin, xmax, slope=5.0):\n",
    "        super().__init__()\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.slope = slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Apply soft clipping using tanh activation function.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor to be soft clipped.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Soft clipped tensor.\n",
    "        \"\"\"\n",
    "        return x - 1/self.slope * torch.log(1+torch.exp(self.slope*(x-self.xmax))) + 1/self.slope * torch.log(1+torch.exp(-self.slope*(x-self.xmin)))\n",
    "    \n",
    "class SoftClampDerivative(nn.Module):\n",
    "    def __init__(self, xmin, xmax, slope=5.0):\n",
    "        super().__init__()\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.slope = slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 1 - 1/(1+torch.exp(-self.slope*(x-self.xmax))) - 1/(1+torch.exp(+self.slope*(x-self.xmin)))\n",
    "    \n",
    "# Example usage:\n",
    "slope = 5.0\n",
    "xmin = 0.45\n",
    "xmax = 0.9\n",
    "soft_clipper = SoftClamp(xmin, xmax, slope=slope)\n",
    "soft_clipper_derivative = SoftClampDerivative(xmin, xmax, slope=slope)\n",
    "\n",
    "soft_x = torch.arange(-2., 3., 0.01)\n",
    "soft_y = soft_clipper(soft_x)\n",
    "soft_y_derivative = soft_clipper_derivative(soft_x)\n",
    "print(f'Ymin: {soft_y.min().item()}\\t Ymax:{soft_y.max().item()}')\n",
    " \n",
    "fix, ax = plt.subplots()\n",
    "ax.plot(soft_x, soft_x, 'k', linewidth=2, label='x')\n",
    "ax.plot(soft_x, soft_y, 'darkred', linewidth=2, label='SoftClamp(x)')\n",
    "ax.plot(soft_x, soft_y_derivative, '--', color='darkgreen', linewidth=2, label='d/dx SoftClamp(x)')\n",
    "ax.set_ylim([soft_y.min().item()-0.5, soft_y.max().item()+0.5])\n",
    "ax.vlines(x=xmin, ymin=soft_y.min().item()-0.5, ymax=soft_y.max().item()+0.5)\n",
    "ax.vlines(x=xmax, ymin=soft_y.min().item()-0.5, ymax=soft_y.max().item()+0.5)\n",
    "ax.set_xlabel('x')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute derivatives analytically and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def derivative_x(x, y, c):\n",
    "    \"\"\"Compute the polynomial basis and sum the elements weighted by the coefficients.\"\"\"\n",
    "    max_order = int((2 * len(c))**0.5 - 1)\n",
    "    basis_sum = torch.zeros_like(x)\n",
    "    idx = 0\n",
    "    for i in range(max_order+1):\n",
    "        for j in range(max_order - i + 1):\n",
    "            basis_sum += c[idx] * (x**(j-1)) * (y**i) * j\n",
    "            idx += 1\n",
    "    return basis_sum\n",
    "\n",
    "def derivative_y(x, y, c):\n",
    "    \"\"\"Compute the polynomial basis and sum the elements weighted by the coefficients.\"\"\"\n",
    "    max_order = int((2 * len(c))**0.5 - 1)\n",
    "    basis_sum = torch.zeros_like(x)\n",
    "    idx = 0\n",
    "    for i in range(max_order+1):\n",
    "        for j in range(max_order - i + 1):\n",
    "            basis_sum += c[idx] * (x**j) * (y**(i-1)) * i\n",
    "            idx += 1\n",
    "    return basis_sum\n",
    "\n",
    "VGS_vals = np.linspace(0,49,10)\n",
    "fig, ax = plt.subplots(2)\n",
    "fig.set_figwidth(4)\n",
    "fig.set_figheight(6)\n",
    "cmap=cm.coolwarm\n",
    "\n",
    "fit_x_derivative = derivative_x(torch.tensor(X), torch.tensor(Y), torch.tensor(c))\n",
    "x_derivative = fit_x_derivative.T\n",
    "for i, VGS_index in enumerate(VGS_vals):\n",
    "    if Vgs[int(VGS_index)] < vgs_max and Vgs[int(VGS_index)] > vgs_min:\n",
    "        ax[0].plot(Vds, x_derivative[int(VGS_index),:], 'o', ms=2, label=f'Vgs={Vgs[int(VGS_index)]:.2f}', c=cmap(i/len(VGS_vals)))\n",
    "ax[0].set_xlabel(\"Vds [V]\")\n",
    "ax[0].set_ylabel(\"Derivative x\")\n",
    "ax[0].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "fit_y_derivative = derivative_y(torch.tensor(X), torch.tensor(Y), torch.tensor(c))\n",
    "y_derivative = fit_y_derivative.T\n",
    "for i, VDS_index in enumerate(VDS_vals):\n",
    "    if Vds[int(VDS_index)] < vds_max and Vds[int(VDS_index)] > vds_min:\n",
    "        ax[1].plot(Vgs, y_derivative[:,int(VDS_index)], 'o', ms=2, label=f'Vds={Vgs[int(VDS_index)]:.2f}', c=cmap(i/len(VGS_vals)))\n",
    "ax[1].set_xlabel(\"Vgs [V]\")\n",
    "ax[1].set_ylabel(\"Derivative y\")\n",
    "ax[1].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check pytorch gpt DRAM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRAM_MAC_temporal_encoding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 4th order polynomial\n",
    "        c = [-3.44667212, -3.10200491, -2.79180442, -2.51262398, 17.82124636, 16.03912173, 14.43520955, -35.79805338, -32.21824805, 46.05483778]\n",
    "        working_range_x = [0.0, 1.0]\n",
    "        working_range_y = [0.0, 0.9]\n",
    "        self.register_buffer('coefficient', torch.tensor(c), persistent=True)\n",
    "        self.max_order = int((2 * len(c))**0.5 - 1)\n",
    "        print(f\"DRAM MAC temporal encoding model fitted with a {self.max_order} order polynomial working in range [{working_range_x[0]}, {working_range_x[1]}], [{working_range_y[0]}, {working_range_y[1]}].\")\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        \"\"\"Compute the polynomial basis and sum the elements weighted by the coefficients.\"\"\"\n",
    "        x_max = 0.9\n",
    "        idx = 0        \n",
    "        for i in range(self.max_order+1):\n",
    "            for j in range(self.max_order - i + 1):\n",
    "                if idx == 0:\n",
    "                    basis_sum = y.pow(i) * x_max**j * self.coefficient[idx]\n",
    "                else:\n",
    "                    basis_sum.add_(y.pow(i) * x_max**j * self.coefficient[idx])\n",
    "                idx += 1\n",
    "        # basis_sum = torch.matmul(x, basis_sum)        \n",
    "        # return basis_sum\n",
    "        basis_sum = torch.mul(x, basis_sum)        \n",
    "        return basis_sum\n",
    "    \n",
    "dram_temporal_encoding = DRAM_MAC_temporal_encoding()\n",
    "\n",
    "n_x = 64\n",
    "n_y = 64\n",
    "n_D = 32\n",
    "x = torch.rand(n_x, n_D)\n",
    "y = torch.rand(n_y, n_D) * 0.9\n",
    "x = x.unsqueeze(1).expand(-1, n_y, -1)\n",
    "y = y.unsqueeze(0).expand(n_x, -1, -1)\n",
    "z_temporal = dram_temporal_encoding(x, y)\n",
    "basis = get_custom_basis(x.flatten(), y.flatten()-offsets)\n",
    "# Linear, least-squares fit.\n",
    "A = np.vstack(basis).T\n",
    "b = z_temporal.ravel()\n",
    "c_linear, r, rank, s = np.linalg.lstsq(A, b, rcond=None)\n",
    "print('Fitted parameters:')\n",
    "print(c_linear)\n",
    "fit_linear = poly_torch_linear(x, y-offsets, torch.tensor(c_linear))\n",
    "r2 = r2_score(z_temporal.flatten(), fit_linear.flatten())\n",
    "print('R² with random input values:', r2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fit_linear.flatten(), fit_linear.flatten(), s=0.01, color='black')\n",
    "ax.scatter(fit_linear.flatten(), z_temporal.flatten(), s=0.01, color='red')\n",
    "plt.show()\n",
    "\n",
    "n_samples = 100\n",
    "x = torch.linspace(0.0, 1.0, n_samples)\n",
    "# x = torch.ones(n_samples)\n",
    "y = torch.linspace(0.00, 0.9, n_samples)\n",
    "x = x.unsqueeze(-1).expand(-1, n_samples)\n",
    "y = y.unsqueeze(0).expand(n_samples, -1)\n",
    "\n",
    "# for i in range(n_samples): \n",
    "#     z_temporal = torch.cat((z_temporal, dram_temporal_encoding(x[i, 0].unsqueeze(0), y[0, :])), dim=0)\n",
    "z_temporal = dram_temporal_encoding(x, y)\n",
    "\n",
    "fit_linear = poly_torch_linear(x, y-offsets, torch.tensor(c_linear))\n",
    "rms = np.sqrt(np.mean((z_temporal.numpy() - fit_linear.numpy())**2))\n",
    "rms_torch = np.sqrt(np.mean((z_temporal.numpy() - fit_linear.numpy())**2))\n",
    "r2 = r2_score(z_temporal, fit_linear)\n",
    "print('R² =', r2, '\\tRMS residual =', rms, '\\t STD of Iout =', np.std(Z))\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "fig.set_figwidth(4)\n",
    "fig.set_figheight(6)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    ax[0].plot(x[:, 0], z_temporal[:, i], 'o', ms=1, c=cmap(i/n_samples))\n",
    "    ax[1].plot(y[0, :], z_temporal[i, :], 'o', ms=1, c=cmap(i/n_samples))\n",
    "    ax[0].plot(x[:, 0], fit_linear[:, i], '--', linewidth=0.5, c=cmap(i/n_samples))\n",
    "    ax[1].plot(y[0, :], fit_linear[i, :], '--', linewidth=0.5, c=cmap(i/n_samples))  \n",
    "\n",
    "ax[0].set_xlabel('x')\n",
    "ax[0].set_ylabel('z')\n",
    "ax[1].set_xlabel('y')\n",
    "ax[1].set_ylabel('z')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sigmoid CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def combined_sigmoid_torch(x, window_center, window_width, stiffness=10):\n",
    "    \"\"\"\n",
    "    Combine two sigmoid functions to produce a function close to 1 within a window\n",
    "    and close to 0 outside the window.\n",
    "\n",
    "    Parameters:\n",
    "        x (torch.Tensor): Input tensor.\n",
    "        window_center (float): Center of the window.\n",
    "        window_width (float): Width of the window.\n",
    "        stiffness (float, optional): Steepness of the sigmoid functions. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Output tensor of the combined sigmoid function.\n",
    "    \"\"\"\n",
    "    sigmoid_1 = torch.sigmoid(stiffness * (x - window_center + window_width / 2))\n",
    "    sigmoid_2 = torch.sigmoid(stiffness * (x - window_center - window_width / 2))\n",
    "    \n",
    "    return sigmoid_1 * (1 - sigmoid_2)\n",
    "\n",
    "class _args():\n",
    "    def __init__(self) -> None:\n",
    "        self.cam_stiffness = 200.\n",
    "        self.cam_width = 0.1\n",
    "        self.trainable_cam_parameters = False\n",
    "args = _args()\n",
    "x = torch.arange(-0.2, 0.2, 0.001)\n",
    "\n",
    "# Example usage\n",
    "window_center = 0.0\n",
    "window_width = args.cam_width\n",
    "stiffness = args.cam_stiffness\n",
    "# window_width = 0.1\n",
    "# stiffness = 10\n",
    "\n",
    "y_values = combined_sigmoid_torch(x, window_center, window_width, stiffness=stiffness)\n",
    "\n",
    "# Plotting\n",
    "\n",
    "plt.plot(x.numpy(), y_values.numpy())\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Combined Sigmoid Output')\n",
    "plt.title('Combined Sigmoid Function')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a CAM output in function of window center and input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CAMTransformer(nn.Module):\n",
    "#     def __init__(self, dim_in, dim_out, center) -> None:\n",
    "#         super().__init__()\n",
    "#         self.cam = aCAM_NOR(dim_in, dim_out,                         \n",
    "#                             stiffness=stiffness, \n",
    "#                             center=center,\n",
    "#                             width=0.1,                                                       \n",
    "#                             )\n",
    "#     def forward(self, x):\n",
    "#         x = self.cam(x.unsqueeze(0).unsqueeze(-1))\n",
    "#         return x[0]\n",
    "\n",
    "def tanh_approximation(x, y, stiffness):\n",
    "    x = stiffness*(x-y)\n",
    "    return x - x**3 / 3 # + 2*x**5 / 15 # - 17*x**7 / 315\n",
    "\n",
    "def gaussian(x, y, width):\n",
    "    x = (x-y)/width\n",
    "    return torch.exp(-x**2)\n",
    "\n",
    "def approx_gaussian(x, y, width):\n",
    "    x = (x-y)/width\n",
    "    return 2.0188/(1.2006+x**2) + 0.4473/(1.1776+x**2) - 3./(2.9089+x**2)\n",
    "\n",
    "def approx_grad_gaussian(x, y, width):\n",
    "    dif = (x-y)/width\n",
    "    output = torch.zeros_like(dif).to(dif.device)\n",
    "    sup_cond = torch.logical_and(dif>=0, dif<=1.)\n",
    "    output[sup_cond] = - np.sqrt(np.log(2)) / (2*width) * (x[sup_cond] - y - width*np.sqrt(np.log(2)))\n",
    "    inf_cond = torch.logical_and(dif<0, dif>=-1.)\n",
    "    output[inf_cond] = + np.sqrt(np.log(2)) / (2*width) * (x[inf_cond] - y + width*np.sqrt(np.log(2)))\n",
    "    else_cond = torch.logical_or(dif<-1., dif>1.)\n",
    "    output[else_cond] = 0.\n",
    "    return output\n",
    "\n",
    "def CAM_approximation(x, y, stiffness=20., width=0.1):\n",
    "    # out = (-(0.5*tanh_approximation(x, y-width/2, stiffness) - .5)) + ((0.5*tanh_approximation(x, y+width/2, stiffness) + .5))\n",
    "    # return ((0.5*tanh_approximation(x, y+width/2, stiffness) + .5))\n",
    "    # out =  (-(0.5*torch.tanh(stiffness * (x-(y-width/2))) - .5)) + ((0.5*torch.tanh(stiffness * (x-(y+width/2))) + .5))\n",
    "    # return -(out-1)\n",
    "    return gaussian(x, y, width), approx_gaussian(x, y, width), approx_grad_gaussian(x, y, width)\n",
    "\n",
    "y = 0.0\n",
    "net = CAMSimilarity(args)\n",
    "out = net(x, y)\n",
    "out_g, out_approx_g, out_approx_grad_g = CAM_approximation(x, y, width=width)\n",
    "plt.figure()\n",
    "plt.plot(x.detach(), out.detach())\n",
    "# plt.plot(x.detach(), out_g.detach())\n",
    "# plt.plot(x.detach(), out_approx_g.detach())\n",
    "# plt.plot(x.detach(), out_approx_grad_g.detach())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential decay of capacitor with time constant $\\tau_{decay}=100µs$ and $\\tau_{cycle}=20ns$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50000\n",
    "tau_cycle = 20e-9\n",
    "tau_decay = 1e-4\n",
    "k0 = 1.\n",
    "time = torch.arange(0, n_steps)*tau_cycle\n",
    "\n",
    "# Parallel method\n",
    "k2 = k0 * torch.exp(-time / tau_decay)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(time * 1000, k2)\n",
    "ax.set_xlabel('Time (ms)')\n",
    "ax.set_ylabel('K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative capacitor array writting correlation measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.regression import PearsonCorrCoef\n",
    "tau_cycle = 20e-9 # duration of one read+write cycle\n",
    "tau_decay = 5e-6 # capacitor decay time\n",
    "\n",
    "n_steps = 2048*4 # number of cycles\n",
    "M = 128 # number of capacitors array\n",
    "D = 1024 # size of one capacitor array\n",
    "capacitor = torch.zeros(n_steps, M, D)\n",
    "signals = torch.rand(n_steps, D) # \"signals\" are the memory that we want to store in the capacitors (namely, either the keys or values)\n",
    "\n",
    "decay = tau_cycle/tau_decay\n",
    "decay = torch.clip(decay * (1 + torch.randn(M, D)*0.01), min=0., max=float('inf')) # simulating decay device-to-device variability\n",
    "decay = (1-decay)\n",
    "\n",
    "array_idx = 0\n",
    "for t in range(n_steps):\n",
    "    capacitor[t] = capacitor[t-1] * decay\n",
    "    capacitor[t, array_idx] += signals[t]\n",
    "    array_idx += 1\n",
    "    array_idx = array_idx % M\n",
    "\n",
    "# Measuring correlations of the array # array\n",
    "array = 0\n",
    "signals = signals[array::M].unsqueeze(0).expand(n_steps, -1, -1)\n",
    "n_signals = signals[::M].shape[0]\n",
    "correlations = torch.zeros(n_steps, n_signals)\n",
    "for t in range(n_steps):\n",
    "    # Pearson correlation coefficient    \n",
    "    correlations[t] = PearsonCorrCoef(num_outputs = n_signals)(capacitor[t, array].unsqueeze(1).expand(-1, n_signals), signals[t].transpose(0,1))\n",
    "    # Euclidian sim\n",
    "    # correlations[t] = 1 / (1+torch.sqrt(torch.sum((signals[t] - capacitor[t, 0].unsqueeze(0)) ** 2, dim=1)))\n",
    "    # Dot product\n",
    "    # correlations[t] = (signals[t] @ capacitor[t, 0].unsqueeze(1)).squeeze()\n",
    "    # Cosine similarity\n",
    "    # correlations[t] = nn.CosineSimilarity(dim=1)(signals[t], capacitor[t, 0].unsqueeze(0))\n",
    "# Correlation\n",
    "# correlations, lags = scipy_autocorrelate(capacitor[:, 0].transpose(0,1), capacitor[:, 0].transpose(0,1), mode='same'), scipy_correlation_lags(len(capacitor[:, 0].transpose(0,1)), len(capacitor[:, 0].transpose(0,1)), mode='same')\n",
    "# correlations = torch.sum(torch.tensor(correlations), dim=0)\n",
    "    \n",
    "time = torch.arange(0, n_steps)# * tau_cycle\n",
    "fig, ax = plt.subplots(2)\n",
    "\n",
    "ax[0].plot(time, capacitor[:, array].norm(dim=1))\n",
    "ax[0].set_xlabel('Time steps')\n",
    "ax[0].set_ylabel('Capacitor norm')\n",
    "\n",
    "colors = cm.magma\n",
    "\n",
    "for s in range(n_signals):\n",
    "# for s in range(1):\n",
    "    # ax[1].plot(time*1e+6, correlations[:, s], label=f'signal #{s}')\n",
    "    # ax[1].plot(time[0:63], correlations[0:63, s], label=f'signal #{s}')\n",
    "    ax[1].plot(time[s*M:], correlations[s*M:, s], color = colors(s/n_signals), label=f'signal #{s}')\n",
    "    \n",
    "# ax.set_xlabel('Time (µs)')\n",
    "ax[1].set_xlabel('Time steps')\n",
    "ax[1].set_ylabel('Correlation')\n",
    "# ax[1].legend()\n",
    "fig.tight_layout() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- y = x CAM curve -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.arange(-1, 1.01, 0.01)\n",
    "# y = x\n",
    "# out = torch.zeros_like(x)\n",
    "# for j in range(x.shape[0]):\n",
    "#     net = CAMTransformer(1, 1, center=y[j])\n",
    "#     out[j] = net(x)[j]\n",
    "#     # print(x[j])\n",
    "#     # print(y[j])\n",
    "# plt.figure()\n",
    "# plt.plot(x.detach(), out.detach())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential product $e^{xy}$ similarity score curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class exp_score(nn.Module):\n",
    "    def __init__(self, y) -> None:\n",
    "        super().__init__()\n",
    "        self.y = y\n",
    "    def forward(self, x):\n",
    "        return torch.exp(x*self.y)\n",
    "\n",
    "x = torch.arange(-1, 1, 0.01)\n",
    "y = torch.arange(-1,1.1,0.2)\n",
    "\n",
    "colors = cm.coolwarm\n",
    "fig = plt.figure()\n",
    "for j in range(y.shape[0]):\n",
    "    score = exp_score(y[j])\n",
    "    out = score(x)\n",
    "    plt.plot(x.detach(), out.detach(), c=colors(j/y.shape[0]), label=f'y={y[j]:.1f}')\n",
    "fig.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAM similarity surface plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAM_surface_plot(y_bounds, elev, azim, roll):\n",
    "    fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "    y_bounds\n",
    "\n",
    "    x = torch.arange(y_bounds[0], y_bounds[1], 0.01)\n",
    "    # y = x.clone()\n",
    "    y = torch.arange(y_bounds[0], y_bounds[1], 0.01)\n",
    "    Z = torch.zeros(x.shape[0], y.shape[0])\n",
    "    for j in range(y.shape[0]):\n",
    "        net = CAMTransformer(1, 1, center=y[j])\n",
    "        Z[:, j] = net(x)\n",
    "        \n",
    "    # Plot the surface.\n",
    "    X = x.unsqueeze(1).expand(-1, y.shape[0]).detach().cpu().numpy()\n",
    "\n",
    "    Y = y.unsqueeze(1).expand(-1, x.shape[0]).transpose(0,1).detach().cpu().numpy()\n",
    "\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                           linewidth=0,\n",
    "                        antialiased=True,\n",
    "                        )\n",
    "\n",
    "    # Customize the z axis.\n",
    "    ax.zaxis.set_major_locator(LinearLocator(5))\n",
    "    # A StrMethodFormatter is used automatically\n",
    "    ax.zaxis.set_major_formatter('{x:.01f}')\n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf,\n",
    "                shrink=0.5,\n",
    "                #  aspect=5\n",
    "                )\n",
    "    ax.set_xlabel('Q')\n",
    "    ax.set_ylabel('K')\n",
    "    ax.set_zlabel('Similarity')\n",
    "    ax.set_title('$CAM(Q,K)$')\n",
    "    \n",
    "    ax.view_init(elev=elev, azim=azim, roll=roll)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "wb = widgets.interact(CAM_surface_plot,\n",
    "                      y_bounds=widgets.FloatRangeSlider(value=[-1, 1], min=-2.0, max=2.0, step=0.1),\n",
    "                      elev=widgets.FloatSlider(value=30, min=0, max=90, step=1),\n",
    "                      azim=widgets.FloatSlider(value=30, min=-180, max=180, step=1),\n",
    "                      roll=widgets.FloatSlider(value=0, min=-180, max=180, step=1),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential product $e^{xy}$ similarity score surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_score_surface_plot(y_bounds, elev, azim, roll):\n",
    "    fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "    \n",
    "    x = torch.arange(y_bounds[0], y_bounds[1], 0.01).unsqueeze(1)\n",
    "    y = x.transpose(0,1) \n",
    "    Z = torch.exp(x*y)\n",
    "    # Z /= torch.sum(Z, dim=-1).unsqueeze(1)\n",
    "    X, Y, Z = x.detach().cpu().numpy(), y.detach().cpu().numpy(), Z.detach().cpu().numpy()\n",
    "\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                        #    linewidth=0,\n",
    "                        antialiased=True,\n",
    "                        )\n",
    "\n",
    "    # Customize the z axis.\n",
    "    ax.zaxis.set_major_locator(LinearLocator(5))\n",
    "    # A StrMethodFormatter is used automatically\n",
    "    ax.zaxis.set_major_formatter('{x:.01f}')\n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf,\n",
    "                shrink=0.5,\n",
    "                #  aspect=5\n",
    "                )\n",
    "    ax.set_xlabel('Q')\n",
    "    ax.set_ylabel('K')\n",
    "    ax.set_zlabel('Similarity')\n",
    "    ax.set_title('$e^{QK}$')\n",
    "    \n",
    "    ax.view_init(elev=elev, azim=azim, roll=roll)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "wb = widgets.interact(exp_score_surface_plot,\n",
    "                      y_bounds=widgets.FloatRangeSlider(value=[-1, 1], min=-2.0, max=2.0, step=0.1),\n",
    "                      elev=widgets.FloatSlider(value=30, min=0, max=90, step=1),\n",
    "                      azim=widgets.FloatSlider(value=30, min=-180, max=180, step=1),\n",
    "                      roll=widgets.FloatSlider(value=0, min=-180, max=180, step=1),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transistor function:\n",
    "\n",
    "- $I_{DS}=0$ if $V_{GS}\\leq V_{T}$\n",
    "- $I_{DS}=\\mu_{n}C_{ox}\\frac{W}{L}\\left[\\left(V_{GS}-V_{T}\\right)V_{DS}-\\frac{V_{DS}^{2}}{2}\\right]\\left(1+\\lambda V_{DS}\\right)$ if $V_{GS}\\geq V_{T}$, $V_{DS}\\leq V_{GS}-V_{T}$\n",
    "- $I_{DS}=\\frac{1}{2}\\mu_{n}C_{ox}\\frac{W}{L}\\left(V_{GS}-V_{T}\\right)^{2}\\left(1+\\lambda V_{DS}\\right)$ if $V_{GS}\\geq V_{T}$, $V_{DS}> V_{GS}-V_{T}$\n",
    "\n",
    "Let's call:\n",
    "- $\\gamma = \\mu_{n}C_{ox}\\frac{W}{L}$ -> The conductance per volt. Typically $\\gamma$ = 100 µS/V (we normalize to $\\gamma$ = 1 to get normal output values)\n",
    "- $\\lambda$ = 0.05 V\n",
    "- $x = V_{DS}$ is the input\n",
    "- $w = V_{GS}$ is the weight (stored in a capacitor)\n",
    "\n",
    "https://inst.eecs.berkeley.edu/~ee105/fa05/handouts/discussions/Discussion5.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_th = 0.0 # V threshold\n",
    "v_ds_min = 0.0\n",
    "v_ds_max = 1.0\n",
    "\n",
    "v_gs_min = 0.0\n",
    "v_gs_max = 1.0\n",
    "\n",
    "_gamma = 1.\n",
    "_lambda = 0.05\n",
    "\n",
    "def transistor_model(x, w, v_th=.5, _gamma=1., _lambda=.05):\n",
    "    over_threshold = w > v_th\n",
    "    lin_cond = (x - (w-v_th) <= 0) * over_threshold\n",
    "    sat_cond = (x - (w-v_th) > 0) * over_threshold # Saturated when the input voltage is larger that the overdrive and overdrive positive\n",
    "    w = w.expand_as(lin_cond)\n",
    "    x = x.expand_as(lin_cond)\n",
    "    out = torch.zeros_like(lin_cond, dtype=torch.float, device=x.device)\n",
    "    out[lin_cond] = ((w[lin_cond] - v_th)*x[lin_cond] - x[lin_cond]**2/2) * (1 + _lambda*x[lin_cond])\n",
    "    out[sat_cond] = 1/2 * (w[sat_cond] - v_th)**2 * (1 + _lambda*x[sat_cond])\n",
    "    # out = ((w - v_th)*x - x**2/2) * (1 + _lambda*x)\n",
    "    # out = ((w - v_th)*x) * (1 + _lambda*x)\n",
    "    # out = (w - v_th)*x - x**2/2\n",
    "    pre_sum = out\n",
    "    out = torch.sum(out, dim=-2)#.unsqueeze(-1).expand(-1,-1,D)\n",
    "    out = out * _gamma\n",
    "    return out, pre_sum\n",
    "\n",
    "fig, ax = plt.subplots(3)\n",
    "fig.set_figwidth(9)\n",
    "fig.set_figheight(18)\n",
    "\n",
    "# Sweep input for multiple weights\n",
    "x = torch.linspace(v_ds_min, v_ds_max, 100).unsqueeze(0).unsqueeze(0)\n",
    "w = torch.linspace(v_gs_min, v_gs_max, 10).unsqueeze(-1).unsqueeze(-1)\n",
    "out, _ = transistor_model(x, w, v_th, _gamma, _lambda)\n",
    "colors = cm.coolwarm\n",
    "\n",
    "for i in range(out.shape[0]):\n",
    "    ax[0].plot(x.squeeze(), out[i], c=colors(i/out.shape[0]), linewidth=2)    \n",
    "w_sat = x + v_th # Saturation limit\n",
    "out_sat, _ = transistor_model(x, w_sat, v_th, _gamma, _lambda)\n",
    "ax[0].plot(x.squeeze(), out_sat.squeeze(), '--k', linewidth=2)\n",
    "ax[0].set_xlabel('$V_{DS}$')\n",
    "ax[0].set_ylabel('$I_{out}$')\n",
    "\n",
    "for i in range(out.shape[1]//10):\n",
    "    ax[1].plot(w.squeeze(), out[:, i*10], c=colors(i/(out.shape[1]//10)), linewidth=2)\n",
    "x_sat = w - v_th # Saturation limit\n",
    "out_sat, _ = transistor_model(x_sat, w, v_th, _gamma, _lambda)\n",
    "ax[1].plot(w.squeeze(), out_sat.squeeze(), '--k', linewidth=2)\n",
    "ax[1].set_xlabel('$V_{GS}$')\n",
    "ax[1].set_ylabel('$I_{out}$')\n",
    "\n",
    "# Many inputs and weights\n",
    "T = 1024 # number of tokens\n",
    "D = 64 # feature dimension\n",
    "M = 128  # time memory dimension\n",
    "x = torch.rand(T, M, D) * (v_ds_max - v_ds_min) + v_ds_min\n",
    "w = torch.rand(T, M, 1) * (v_gs_max - v_gs_min) + v_gs_min\n",
    "out, pre_sum = transistor_model(x, w, v_th, _gamma, _lambda)\n",
    "\n",
    "# Sweep both input and weights\n",
    "ax[2].scatter(_gamma * (x * (w-v_th)).sum(dim=1).flatten(), out.flatten(), s=1, c='darkblue')\n",
    "\n",
    "# Fit\n",
    "# linearized_xw = _gamma * (x * (w-v_th)).sum(dim=1).flatten()\n",
    "# def linear_fit(x, a, b):\n",
    "#     return a + b * x\n",
    "# popt, pcov = curve_fit(linear_fit, linearized_xw.numpy(), out.flatten().numpy())\n",
    "# print(popt)\n",
    "linearized_xw = _gamma * (x * (w-v_th)).flatten()\n",
    "pre_sum = pre_sum.flatten()\n",
    "def linear_fit(x, a, b):\n",
    "    return a + b * x\n",
    "popt, pcov = curve_fit(linear_fit, linearized_xw.numpy(), pre_sum.numpy())\n",
    "print(popt)\n",
    "\n",
    "popt = tuple(popt)\n",
    "out = linear_fit(linearized_xw, *popt)\n",
    "out = torch.tensor(out).reshape(T, M, D).sum(dim=-2).flatten()\n",
    "linearized_xw = torch.tensor(linearized_xw).reshape(T, M, D).sum(dim=-2).flatten()\n",
    "ax[2].plot(linearized_xw, out, 'r--',linewidth=2)\n",
    "\n",
    "ax[2].set_xlabel('$\\gamma V_{GS}V_{DS}$')\n",
    "ax[2].set_ylabel('$I_{out}$')\n",
    "\n",
    "# Sweeping the weights for a single input feature dim\n",
    "# ax[2].scatter((w[:,:,0]).flatten(), out[:,:,0].flatten(), s=1, c='darkblue')\n",
    "# ax[2].set_xlabel('$V_{GS}$')\n",
    "# ax[2].set_ylabel('$I_{out}$')\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paul's simulation data for transistors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load with numpy.load\n",
    "data = np.load(\"transistor.npy\",allow_pickle=True)\n",
    "Vds = data.item().get(\"Vds\")\n",
    "Vgs = data.item().get(\"Vgs\")\n",
    "Ids = data.item().get(\"Ids\")\n",
    "Ids *= 1000\n",
    "\n",
    "vds_min = -0.21\n",
    "vds_max = 0.21\n",
    "\n",
    "vgs_min = 0.5\n",
    "vgs_max = 1.1\n",
    "\n",
    "VGS_vals = np.linspace(0,99,10)\n",
    "fig, ax = plt.subplots(2)\n",
    "fig.set_figwidth(7)\n",
    "fig.set_figheight(11)\n",
    "cmap=cm.coolwarm\n",
    "for i, VGS_index in enumerate(VGS_vals):\n",
    "    if Vgs[int(VGS_index)] < vgs_max and Vgs[int(VGS_index)] > vgs_min:\n",
    "        ax[0].plot(Vds, Ids[int(VGS_index),:], 'o', ms=5, label=f'Vgs={Vgs[int(VGS_index)]:.2f}', c=cmap(i/len(VGS_vals)))\n",
    "# ax[0].legend()\n",
    "ax[0].set_xlabel(\"Vds [V]\")\n",
    "ax[0].set_ylabel(\"Ids [mA]\")\n",
    "\n",
    "VDS_vals = np.linspace(0,99,10)\n",
    "for VDS_index in VDS_vals:\n",
    "    ax[1].plot(Vgs, Ids[:, int(VDS_index)], 'o', ms=5, label=\"Vds=\"+str(Vds[int(VDS_index)]))\n",
    "# ax[1].legend()\n",
    "ax[1].set_xlabel(\"Vgs [V]\")\n",
    "ax[1].set_ylabel(\"Ids [mA]\")\n",
    "fig.tight_layout()\n",
    "\n",
    "#surface plot of the current\n",
    "Vds3d, Vgs3d = np.meshgrid(Vds, Vgs)\n",
    "fig = plt.figure()\n",
    "ax3d = plt.axes(projection ='3d')\n",
    "surf = ax3d.plot_surface(Vds3d, Vgs3d, Ids, cmap=cm.coolwarm)\n",
    "ax3d.set_xlabel(\"Vds [V]\")\n",
    "ax3d.set_ylabel(\"Vgs [V]\")\n",
    "ax3d.set_zlabel(\"I [mA]\")\n",
    "ax3d.set_title(\"Current\")\n",
    "\n",
    "# fit the curves\n",
    "def transistor_polynomial(xy, a, b, c, d, e, f,\n",
    "                          g,\n",
    "                          h,\n",
    "                          i,\n",
    "                          j,\n",
    "                          ):\n",
    "    x, y = xy\n",
    "    return a + b*x + c*y + d*x**2 + e*y**2 + f*x*y + g*x**3 + h*y**3 + i*x**2*y + j*x*y**2\n",
    "\n",
    "condition = (Vds3d < vds_max) * (Vds3d > vds_min) * (Vgs3d < vgs_max) * (Vgs3d > vgs_min)\n",
    "n_args = len(getargspec(transistor_polynomial).args) - 1\n",
    "popt, pcov = curve_fit(transistor_polynomial, (Vds3d[condition].flatten(), Vgs3d[condition].flatten()), Ids[condition].flatten(),\n",
    "                       bounds=(np.concatenate((np.array([-1e-8]), np.array([-np.inf for i in range(n_args-1)]))), np.concatenate((np.array([+1e-8]), np.array([+np.inf for i in range(n_args-1)])))),\n",
    "                       )\n",
    "\n",
    "popt = tuple(popt)\n",
    "Ids_fit = transistor_polynomial((Vds3d.flatten(), Vgs3d.flatten()), *popt)\n",
    "Ids_fit = Ids_fit.reshape((100,101))\n",
    "\n",
    "for i, VGS_index in enumerate(VGS_vals):\n",
    "    if Vgs[int(VGS_index)] < vgs_max and Vgs[int(VGS_index)] > vgs_min:\n",
    "        ax[0].plot(Vds, Ids_fit[int(VGS_index),:], '-', linewidth=2, c=cmap(i/len(VGS_vals)))\n",
    "ax[0].set_xlim([vds_min, vds_max])\n",
    "ax[0].set_ylim([-0.1, 0.1])\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Vds [V]\")\n",
    "ax[0].set_ylabel(\"Ids [mA]\")\n",
    "print(popt)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25e21116bdf790d98d7fe35f39684394c22489b50b9fced1dce0e2c23ed6ff5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
